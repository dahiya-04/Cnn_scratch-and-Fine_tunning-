{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiiWwb0DhNJC",
        "outputId": "70d876e8-2aae-4bfd-c257-4a807689f009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/kabilan03/dogbreedclassification?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 272M/272M [00:01<00:00, 145MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/kabilan03/dogbreedclassification/versions/3\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kabilan03/dogbreedclassification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "ne = os.listdir(path)\n",
        "os.path.join(path,ne[0])\n",
        "new = (os.path.join(path,ne[0]))\n",
        "new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pHMGsCjnhRm5",
        "outputId": "fc6934bb-5bc9-449c-8dc1-f6b52ee305f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/kagglehub/datasets/kabilan03/dogbreedclassification/versions/3/Dog Breed Classification'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import image\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self,image_dir,transform=None):\n",
        "      self.image_dir = image_dir\n",
        "\n",
        "      self.transform = transform\n",
        "      self.image =[]\n",
        "      self.labels = []\n",
        "\n",
        "      for i ,class_name in enumerate(sorted(os.listdir(self.image_dir))):\n",
        "        class_path = os.path.join(self.image_dir,class_name)\n",
        "\n",
        "        if not os.path.isdir(class_path):\n",
        "                continue\n",
        "        for image_path in os.listdir(class_path):\n",
        "          self.image.append(os.path.join(class_path,image_path))\n",
        "          self.labels.append(i)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.image)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "      image_path = self.image[idx]\n",
        "      label = self.labels[idx]\n",
        "      img = Image.open(image_path).convert(\"RGB\")\n",
        "      # print(img.size)\n",
        "\n",
        "      if self.transform:\n",
        "        img = self.transform(img)\n",
        "\n",
        "\n",
        "      return img,label\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mraF6PhmiOoh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from tensorflow import image\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((180, 180)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(), # Moved ToTensor before Normalize\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = ImageDataset(\n",
        "    image_dir=\"/root/.cache/kagglehub/datasets/kabilan03/dogbreedclassification/versions/3/Dog Breed Classification/train\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "val_dataset = ImageDataset(\n",
        "    image_dir =\"/root/.cache/kagglehub/datasets/kabilan03/dogbreedclassification/versions/3/Dog Breed Classification/val\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# print(len(train_dataset))\n",
        "# img, label = train_dataset[69]\n",
        "# print(label,img)"
      ],
      "metadata": {
        "id": "ypEt9LoOhaxM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_class_count = {}\n",
        "\n",
        "for img, label in train_dataset:\n",
        "    if label in train_class_count:\n",
        "        train_class_count[label] += 1\n",
        "    else:\n",
        "        train_class_count[label] = 1\n",
        "\n",
        "print(train_class_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL2Sm2qvhjY1",
        "outputId": "b34bd273-7900-41e5-b286-9e7ea1d2eb6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 92, 1: 68, 2: 85, 3: 88, 4: 65, 5: 84, 6: 71, 7: 91, 8: 61, 9: 81, 10: 68, 11: 68, 12: 57, 13: 72, 14: 60, 15: 69, 16: 68, 17: 53, 18: 60, 19: 84, 20: 60, 21: 66, 22: 74, 23: 64, 24: 59, 25: 69, 26: 57, 27: 60, 28: 64, 29: 59, 30: 68, 31: 66, 32: 92, 33: 57, 34: 55, 35: 60, 36: 53, 37: 64, 38: 60, 39: 88, 40: 65, 41: 72, 42: 70, 43: 65, 44: 62, 45: 80, 46: 84, 47: 64, 48: 65, 49: 53, 50: 56, 51: 67, 52: 84, 53: 72, 54: 64, 55: 58, 56: 93, 57: 64, 58: 81, 59: 62, 60: 72, 61: 66, 62: 76, 63: 62, 64: 69, 65: 55, 66: 76, 67: 60, 68: 73, 69: 88, 70: 75, 71: 57, 72: 70, 73: 60, 74: 67, 75: 79, 76: 87, 77: 68, 78: 65, 79: 100, 80: 70, 81: 60, 82: 63, 83: 57, 84: 62, 85: 55, 86: 85, 87: 63, 88: 56, 89: 68, 90: 76, 91: 65, 92: 65}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_class_count ={}\n",
        "\n",
        "for img ,  label in val_dataset:\n",
        "  if label in val_class_count:\n",
        "    val_class_count[label] += 1\n",
        "  else:\n",
        "    val_class_count[label] =1\n",
        "print(val_class_count)\n",
        "print(len(val_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uep0XBc4ixJO",
        "outputId": "f975853f-e045-41e6-cd4a-5001b51b783c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 11, 1: 8, 2: 10, 3: 11, 4: 8, 5: 10, 6: 8, 7: 11, 8: 7, 9: 10, 10: 8, 11: 8, 12: 7, 13: 9, 14: 7, 15: 8, 16: 8, 17: 6, 18: 7, 19: 10, 20: 7, 21: 8, 22: 9, 23: 8, 24: 7, 25: 8, 26: 7, 27: 7, 28: 8, 29: 7, 30: 8, 31: 8, 32: 11, 33: 7, 34: 6, 35: 7, 36: 6, 37: 8, 38: 7, 39: 11, 40: 8, 41: 9, 42: 8, 43: 8, 44: 7, 45: 10, 46: 10, 47: 8, 48: 8, 49: 6, 50: 7, 51: 8, 52: 10, 53: 9, 54: 8, 55: 7, 56: 11, 57: 8, 58: 10, 59: 7, 60: 9, 61: 8, 62: 9, 63: 7, 64: 8, 65: 6, 66: 9, 67: 7, 68: 9, 69: 11, 70: 9, 71: 7, 72: 8, 73: 7, 74: 8, 75: 9, 76: 10, 77: 8, 78: 8, 79: 12, 80: 8, 81: 7, 82: 7, 83: 7, 84: 7, 85: 6, 86: 10, 87: 7, 88: 7, 89: 8, 90: 9, 91: 8, 92: 8}\n",
            "762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "def accuracy(output,target):\n",
        "  predict = torch.argmax(output,dim=1)\n",
        "  correct =(predict == target).sum().item()\n",
        "  return correct/len(target)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(model,train_loader,optimizer,criterio,device):\n",
        "      model.train()\n",
        "\n",
        "      running_loss =0\n",
        "      running_acc = 0\n",
        "      total_sample =0\n",
        "\n",
        "      for images , labels in train_loader:\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(images)\n",
        "        loss =criterio(output,labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() *labels.size(0)\n",
        "        running_acc += accuracy(output,labels) *labels.size(0)\n",
        "        total_sample += len(labels)\n",
        "\n",
        "      epoch_loss = running_loss / total_sample\n",
        "      epoch_acc = running_acc / total_sample\n",
        "      return epoch_loss,epoch_acc\n",
        "\n",
        "def validate(model,val_loader,criterio,device):\n",
        "      model.eval()\n",
        "\n",
        "      running_loss =0\n",
        "      running_acc = 0\n",
        "      total_sample =0\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for images ,labels in val_loader:\n",
        "          images,labels = images.to(device),labels.to(device)\n",
        "          output = model(images)\n",
        "\n",
        "          loss = criterio(model(images),labels)\n",
        "\n",
        "          running_loss += loss.item() *labels.size(0)\n",
        "          running_acc += accuracy(output,labels) *labels.size(0)\n",
        "          total_sample += len(labels)\n",
        "      total_loss = running_loss / total_sample\n",
        "      epoch_acc = running_acc / total_sample\n",
        "      return total_loss,epoch_acc\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FvKv44CQjfjN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loader_train = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "loader_val = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "APYnsawLl7k1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pretrained ResNet18\n",
        "model = models.resnet18(\n",
        "    weights=models.ResNet18_Weights.IMAGENET1K_V1\n",
        ")\n",
        "\n",
        "# Freeze ALL layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze last ResNet block\n",
        "\n",
        "for param in model.layer3.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "num_features = model.fc.in_features  # 512\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(num_features, 1024),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(1024, 93)\n",
        ")\n",
        "\n",
        "# Ensure new head is trainable\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer: ONLY trainable parameters\n",
        "optimizer = torch.optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "# History\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_acc\": []\n",
        "}\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(\n",
        "        model, loader_train, optimizer, criterion, device\n",
        "    )\n",
        "    val_loss, val_acc = validate(\n",
        "        model, loader_val, criterion, device\n",
        "    )\n",
        "\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-6\n",
        ")\n",
        "\n",
        "# History\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_acc\": []\n",
        "}\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(\n",
        "        model, loader_train, optimizer, criterion, device\n",
        "    )\n",
        "    val_loss, val_acc = validate(\n",
        "        model, loader_val, criterion, device\n",
        "    )\n",
        "    # if val_loss < best_val_loss:\n",
        "    #     best_val_loss = val_loss\n",
        "    #     torch.save(model.state_dict(),'best_model.pth')\n",
        "\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXR09w1pnOmH",
        "outputId": "6ae3783f-11da-438b-82dc-5cb54620be14"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Train Loss: 3.7809, Train Acc: 0.1566 | Val Loss: 2.3795, Val Acc: 0.4561\n",
            "Epoch 2/5 | Train Loss: 2.2742, Train Acc: 0.3999 | Val Loss: 1.5034, Val Acc: 0.5851\n",
            "Epoch 3/5 | Train Loss: 1.6949, Train Acc: 0.5169 | Val Loss: 1.3263, Val Acc: 0.6316\n",
            "Epoch 4/5 | Train Loss: 1.3644, Train Acc: 0.6006 | Val Loss: 1.2199, Val Acc: 0.6476\n",
            "Epoch 5/5 | Train Loss: 1.1239, Train Acc: 0.6681 | Val Loss: 1.2275, Val Acc: 0.6543\n",
            "Epoch 1/2 | Train Loss: 0.8859, Train Acc: 0.7381 | Val Loss: 1.1521, Val Acc: 0.6755\n",
            "Epoch 2/2 | Train Loss: 0.8629, Train Acc: 0.7497 | Val Loss: 1.1817, Val Acc: 0.6636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AE-jZZWUooeY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}